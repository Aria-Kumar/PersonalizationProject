{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring the Benchmark for the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for the user bias benchmark metric we use in this problem. We define user bias as the percentage of skips per user on average. For example if a user skips a song 10% of the times on average, he/she will be assigned a skip probability of 10% for all future tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score as AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_split(data, validation_ratio = 0.15, test_ratio = 0.15):\n",
    "    \"\"\"\n",
    "    Function to split data into train, validation and test based on timestamps\n",
    "    \n",
    "    https://stackoverflow.com/questions/42395258/\n",
    "    \n",
    "    \"\"\"\n",
    "    train_ratio = 1 - validation_ratio - test_ratio \n",
    "    data['time_rank'] = data.groupby('userid')['timestamp'].rank()\n",
    "    data['user_all_songs_count'] = data['userid'].map(data.groupby('userid')['timestamp'].apply(len))\n",
    "    data['scaled_time_rank'] = data['time_rank']/ data['user_all_songs_count']    \n",
    "    data.drop(['time_rank', 'user_all_songs_count'], axis=1, inplace=True)    \n",
    "    train_data = data.loc[data['scaled_time_rank'] <= train_ratio, :]\n",
    "    validation_data = data.loc[(data['scaled_time_rank'] <= (1 - test_ratio)) & (data['scaled_time_rank'] > train_ratio), :]\n",
    "    test_data = data.loc[(data['scaled_time_rank'] > (train_ratio + validation_ratio)), :]\n",
    "    return train_data, validation_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pandas_df = pd.read_csv('data_engineered_features500.csv') \n",
    "pandas_df = pandas_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = data_split(pandas_df, validation_ratio = 0.15, test_ratio = 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only training data to evaluate the user bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_skips = train_data.groupby(['userid'])['skipped'].sum()\n",
    "user_counts = train_data.groupby(['userid'])['skipped'].count()\n",
    "user_summary_table = pd.concat([user_skips, user_counts], axis=1)\n",
    "user_summary_table.columns = [\"skips\", \"total_count\"]\n",
    "user_summary_table.loc[:,'userid'] = user_summary_table.index\n",
    "user_summary_table.loc[:, 'skip_percent'] = user_summary_table['skips'] / user_summary_table['total_count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.merge(test_data, user_summary_table,\n",
    "                          on = [\"userid\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75926314622341584"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC(np.array(test_data[\"skipped\"]), np.array(test_data[\"skip_percent\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
