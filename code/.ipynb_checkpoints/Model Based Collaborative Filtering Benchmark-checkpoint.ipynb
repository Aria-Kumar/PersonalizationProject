{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import random\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import evaluate, print_perf\n",
    "\n",
    "random.seed(561)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 2120260: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 2446318: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 11141081: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 11152099: expected 6 fields, saw 12\\nSkipping line 11152402: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 11882087: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 12902539: expected 6 fields, saw 8\\nSkipping line 12935044: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 17589539: expected 6 fields, saw 8\\n'\n"
     ]
    }
   ],
   "source": [
    "users = pd.read_table('~/Columbia/Personalization Theory/lastfm-dataset-1K/userid-profile.tsv', header=0)\n",
    "data = pd.read_table('~/Columbia/Personalization Theory/lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv',\n",
    "                     header=-1,\n",
    "                     #nrows=20000000,\n",
    "                     error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={0:'userid', 1:'timestamp', 2:'artistid', 3:'artistname', 4:'trackid', 5:'trackname'})\n",
    "\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the mini-project, we are using a smaller dataset. The following transformations will convert the dataset to use number of plays as our metric, grouped by user and artist.\n",
    "\n",
    "To help with our data cleaning and setting up the matrices, we used [this website](https://jessesw.com/Rec-System/) to guide us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.groupby(['userid', 'artistname']).size().reset_index(name='plays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<992x897419 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 897419 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = list(np.sort(data.userid.unique())) # Get our unique users\n",
    "artists = list(data.artistname.unique()) # Get our unique artists\n",
    "quantity = list(data.plays) # All of our plays\n",
    "\n",
    "rows = data.userid.astype('category', categories = users).cat.codes \n",
    "# Get the associated row indices\n",
    "cols = data.artistname.astype('category', categories = artists).cat.codes \n",
    "# Get the associated column indices\n",
    "plays_sparse = sparse.csr_matrix((quantity, (rows, cols)), shape=(len(users), len(quantity)))\n",
    "plays_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.8991935483871"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sparsity of the matrix\n",
    "matrix_size = plays_sparse.shape[0]*plays_sparse.shape[1] # Number of possible interactions in the matrix\n",
    "num_plays = len(plays_sparse.nonzero()[0]) # Number of items interacted with\n",
    "sparsity = 100*(1 - (num_plays/matrix_size))\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Reduction\n",
    "\n",
    "The sparsity of 99.899% is extremely sparse, even for matrices that are intended to be sparse. We experimented with removing all rare artists, which had minimal effect on the sparsity. Instead, we will include only the top 100 artists, which has some improvement on the sparsity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_artists = data.query(\"plays < 6\"). \\\n",
    "    groupby('artistname').size().reset_index(name='users_listening_to_artist'). \\\n",
    "    query(\"users_listening_to_artist < 10\")\n",
    "    \n",
    "top100_artists = data.groupby('artistname')['plays'].sum().reset_index(name='plays'). \\\n",
    "    nlargest(100,'plays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43179, 3) (897419, 3)\n"
     ]
    }
   ],
   "source": [
    "reduced_data = data[data.artistname.isin(top100_artists['artistname'])]\n",
    "\n",
    "print(reduced_data.shape, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<979x43179 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 43179 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = list(np.sort(reduced_data.userid.unique())) # Get our unique users\n",
    "artists = list(reduced_data.artistname.unique()) # Get our unique artists\n",
    "quantity = list(reduced_data.plays) # All of our plays\n",
    "\n",
    "rows = reduced_data.userid.astype('category', categories = users).cat.codes \n",
    "# Get the associated row indices\n",
    "cols = reduced_data.artistname.astype('category', categories = artists).cat.codes \n",
    "# Get the associated column indices\n",
    "plays_sparse = sparse.csr_matrix((quantity, (rows, cols)), shape=(len(users), len(quantity)))\n",
    "\n",
    "plays_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.89785495403473"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sparsity of the matrix\n",
    "matrix_size = plays_sparse.shape[0]*plays_sparse.shape[1] # Number of possible interactions in the matrix\n",
    "num_plays = len(plays_sparse.nonzero()[0]) # Number of items interacted with\n",
    "sparsity = 100*(1 - (num_plays/matrix_size))\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While 99.898% sparsity is not great, it is an improvement over the previous matrix, and so we will use this to set up our brute force model.\n",
    "\n",
    "For SVD, we use the `surprise` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>artistname</th>\n",
       "      <th>plays</th>\n",
       "      <th>normalized_plays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>Björk</td>\n",
       "      <td>448</td>\n",
       "      <td>0.354150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>Boards Of Canada</td>\n",
       "      <td>180</td>\n",
       "      <td>0.142292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>Coldplay</td>\n",
       "      <td>33</td>\n",
       "      <td>0.026087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>Moby</td>\n",
       "      <td>51</td>\n",
       "      <td>0.040316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>Oasis</td>\n",
       "      <td>22</td>\n",
       "      <td>0.017391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        userid        artistname  plays  normalized_plays\n",
       "0  user_000001             Björk    448          0.354150\n",
       "1  user_000001  Boards Of Canada    180          0.142292\n",
       "2  user_000001          Coldplay     33          0.026087\n",
       "3  user_000001              Moby     51          0.040316\n",
       "4  user_000001             Oasis     22          0.017391"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usertotal = reduced_data.groupby('userid')['plays'].sum().reset_index(name=\"total_plays\")\n",
    "normalized_data = pd.merge(reduced_data, usertotal)\n",
    "normalized_data['normalized_plays'] = normalized_data['plays']/normalized_data['total_plays']\n",
    "normalized_data.drop(['total_plays'], inplace=True, axis=1)\n",
    "\n",
    "normalized_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "RMSE: 0.0595\n",
      "MAE:  0.0322\n",
      "------------\n",
      "Fold 2\n",
      "RMSE: 0.0640\n",
      "MAE:  0.0334\n",
      "------------\n",
      "Fold 3\n",
      "RMSE: 0.0601\n",
      "MAE:  0.0323\n",
      "------------\n",
      "Fold 4\n",
      "RMSE: 0.0585\n",
      "MAE:  0.0322\n",
      "------------\n",
      "Fold 5\n",
      "RMSE: 0.0548\n",
      "MAE:  0.0309\n",
      "------------\n",
      "Fold 6\n",
      "RMSE: 0.0567\n",
      "MAE:  0.0316\n",
      "------------\n",
      "Fold 7\n",
      "RMSE: 0.0645\n",
      "MAE:  0.0333\n",
      "------------\n",
      "Fold 8\n",
      "RMSE: 0.0591\n",
      "MAE:  0.0323\n",
      "------------\n",
      "Fold 9\n",
      "RMSE: 0.0610\n",
      "MAE:  0.0323\n",
      "------------\n",
      "Fold 10\n",
      "RMSE: 0.0593\n",
      "MAE:  0.0320\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 0.0598\n",
      "Mean MAE : 0.0322\n",
      "------------\n",
      "------------\n",
      "        Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Fold 6  Fold 7  Fold 8  Fold 9  Fold 10 Mean    \n",
      "RMSE    0.0595  0.0640  0.0601  0.0585  0.0548  0.0567  0.0645  0.0591  0.0610  0.0593  0.0598  \n",
      "MAE     0.0322  0.0334  0.0323  0.0322  0.0309  0.0316  0.0333  0.0323  0.0323  0.0320  0.0322  \n"
     ]
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(0, 1))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "model_data = Dataset.load_from_df(normalized_data[['userid', 'artistname', 'normalized_plays']], reader)\n",
    "\n",
    "model_data.split(n_folds=10)\n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Evaluate performances of our algorithm on the dataset.\n",
    "perf = evaluate(algo, model_data, measures=['RMSE', 'MAE'])\n",
    "\n",
    "print_perf(perf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
