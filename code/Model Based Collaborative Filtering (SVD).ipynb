{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import random\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import evaluate, print_perf\n",
    "\n",
    "random.seed(561)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 2120260: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 2446318: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 11141081: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 11152099: expected 6 fields, saw 12\\nSkipping line 11152402: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 11882087: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 12902539: expected 6 fields, saw 8\\nSkipping line 12935044: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 17589539: expected 6 fields, saw 8\\n'\n"
     ]
    }
   ],
   "source": [
    "users = pd.read_table('~/Columbia/Personalization Theory/lastfm-dataset-1K/userid-profile.tsv', header=0)\n",
    "data = pd.read_table('~/Columbia/Personalization Theory/lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv',\n",
    "                     header=-1,\n",
    "                     #nrows=20000000,\n",
    "                     error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.rename(columns={0:'userid', 1:'timestamp', 2:'artistid', 3:'artistname', 4:'trackid', 5:'trackname'})\n",
    "\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the mini-project, we are using a smaller dataset. The following transformations will convert the dataset to use number of plays as our metric, grouped by user and artist.\n",
    "\n",
    "To help with our data cleaning and setting up the matrices, we used [this website](https://jessesw.com/Rec-System/) to guide us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.groupby(['userid', 'artistname']).size().reset_index(name='plays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<992x897419 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 897419 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = list(np.sort(data.userid.unique())) # Get our unique users\n",
    "artists = list(data.artistname.unique()) # Get our unique artists\n",
    "quantity = list(data.plays) # All of our plays\n",
    "\n",
    "rows = data.userid.astype('category', categories = users).cat.codes \n",
    "# Get the associated row indices\n",
    "cols = data.artistname.astype('category', categories = artists).cat.codes \n",
    "# Get the associated column indices\n",
    "plays_sparse = sparse.csr_matrix((quantity, (rows, cols)), shape=(len(users), len(quantity)))\n",
    "plays_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.8991935483871"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sparsity of the matrix\n",
    "matrix_size = plays_sparse.shape[0]*plays_sparse.shape[1] # Number of possible interactions in the matrix\n",
    "num_plays = len(plays_sparse.nonzero()[0]) # Number of items interacted with\n",
    "sparsity = 100*(1 - (num_plays/matrix_size))\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Reduction\n",
    "\n",
    "The sparsity of 99.899% is extremely sparse, even for matrices that are intended to be sparse. We experimented with removing all rare artists, which had minimal effect on the sparsity. Instead, we will include only the top 100 artists, which has some improvement on the sparsity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rare_artists = data.query(\"plays < 6\"). \\\n",
    "    groupby('artistname').size().reset_index(name='users_listening_to_artist'). \\\n",
    "    query(\"users_listening_to_artist < 10\")\n",
    "    \n",
    "top100_artists = data.groupby('artistname')['plays'].sum().reset_index(name='plays'). \\\n",
    "    nlargest(100,'plays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(596817, 3) (897419, 3)\n"
     ]
    }
   ],
   "source": [
    "reduced_data = data[~data.artistname.isin(rare_artists['artistname'])]\n",
    "\n",
    "print(reduced_data.shape, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<992x596817 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 596817 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = list(np.sort(reduced_data.userid.unique())) # Get our unique users\n",
    "artists = list(reduced_data.artistname.unique()) # Get our unique artists\n",
    "quantity = list(reduced_data.plays) # All of our plays\n",
    "\n",
    "rows = reduced_data.userid.astype('category', categories = users).cat.codes \n",
    "# Get the associated row indices\n",
    "cols = reduced_data.artistname.astype('category', categories = artists).cat.codes \n",
    "# Get the associated column indices\n",
    "plays_sparse = sparse.csr_matrix((quantity, (rows, cols)), shape=(len(users), len(quantity)))\n",
    "\n",
    "plays_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.8991935483871"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sparsity of the matrix\n",
    "matrix_size = plays_sparse.shape[0]*plays_sparse.shape[1] # Number of possible interactions in the matrix\n",
    "num_plays = len(plays_sparse.nonzero()[0]) # Number of items interacted with\n",
    "sparsity = 100*(1 - (num_plays/matrix_size))\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While 99.898% sparsity is not great, it is an improvement over the previous matrix, and so we will use this to set up our brute force model.\n",
    "\n",
    "For SVD, we use the `surprise` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    596817.000000\n",
       "mean          0.001662\n",
       "std           0.007252\n",
       "min           0.000006\n",
       "25%           0.000087\n",
       "50%           0.000275\n",
       "75%           0.001033\n",
       "max           1.000000\n",
       "Name: normalized_plays, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usertotal = reduced_data.groupby('userid')['plays'].sum().reset_index(name=\"total_plays\")\n",
    "normalized_data = pd.merge(reduced_data, usertotal)\n",
    "normalized_data['normalized_plays'] = normalized_data['plays']/normalized_data['total_plays']\n",
    "normalized_data.drop(['total_plays'], inplace=True, axis=1)\n",
    "#normalized_data['normalized_plays'] = normalized_data['normalized_plays']*4+1\n",
    "\n",
    "normalized_data.normalized_plays.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, FCP of algorithm SVD.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "RMSE: 0.0079\n",
      "FCP:  0.5017\n",
      "------------\n",
      "Fold 2\n",
      "RMSE: 0.0078\n",
      "FCP:  0.5020\n",
      "------------\n",
      "Fold 3\n",
      "RMSE: 0.0080\n",
      "FCP:  0.5003\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 0.0079\n",
      "Mean FCP : 0.5013\n",
      "------------\n",
      "------------\n",
      "        Fold 1  Fold 2  Fold 3  Mean    \n",
      "RMSE    0.0079  0.0078  0.0080  0.0079  \n",
      "FCP     0.5017  0.5020  0.5003  0.5013  \n"
     ]
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(0, 1))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "model_data = Dataset.load_from_df(normalized_data[['userid', 'artistname', 'normalized_plays']], reader)\n",
    "\n",
    "model_data.split(n_folds=3)\n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD(reg_all=.1)\n",
    "\n",
    "# Evaluate performances of our algorithm on the dataset.\n",
    "perf = evaluate(algo, model_data, measures=['RMSE', 'FCP'])\n",
    "\n",
    "print_perf(perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# THEORY: is the model just guessing very low values? Adjust the penalty to remove this possibility"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
