{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import random\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import evaluate, print_perf, GridSearch\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "random.seed(561)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 2120260: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 2446318: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 11141081: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 11152099: expected 6 fields, saw 12\\nSkipping line 11152402: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 11882087: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 12902539: expected 6 fields, saw 8\\nSkipping line 12935044: expected 6 fields, saw 8\\n'\n",
      "b'Skipping line 17589539: expected 6 fields, saw 8\\n'\n"
     ]
    }
   ],
   "source": [
    "# users = pd.read_csv('~/Columbia/Personalization Theory/lastfm-dataset-1K/userid-profile.tsv', header=None)\n",
    "data = pd.read_csv('~/Columbia/Personalization Theory/lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv',\n",
    "                   delimiter=\"\\t\", header=None,\n",
    "                   names = [\"userid\",\"timestamp\",\"artistid\",\n",
    "                            \"artistname\",\"trackid\",\"trackname\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = data.rename(columns={0:'userid', 1:'timestamp', 2:'artistid', 3:'artistname', 4:'trackid', 5:'trackname'})\n",
    "\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the mini-project, we are using a smaller dataset. The following transformations will convert the dataset to use number of plays as our metric, grouped by user and artist.\n",
    "\n",
    "To help with our data cleaning and setting up the matrices, we used [this website](https://jessesw.com/Rec-System/) to guide us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.groupby(['userid', 'artistname']).size().reset_index(name='plays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = list(np.sort(data.userid.unique())) # Get our unique users\n",
    "artists = list(data.artistname.unique()) # Get our unique artists\n",
    "quantity = list(data.plays) # All of our plays\n",
    "\n",
    "rows = data.userid.astype('category', categories = users).cat.codes \n",
    "# Get the associated row indices\n",
    "cols = data.artistname.astype('category', categories = artists).cat.codes \n",
    "# Get the associated column indices\n",
    "plays_sparse = sparse.csr_matrix((quantity, (rows, cols)), shape=(len(users), len(quantity)))\n",
    "plays_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sparsity of the matrix\n",
    "matrix_size = plays_sparse.shape[0]*plays_sparse.shape[1] # Number of possible interactions in the matrix\n",
    "num_plays = len(plays_sparse.nonzero()[0]) # Number of items interacted with\n",
    "sparsity = 100*(1 - (num_plays/matrix_size))\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Reduction\n",
    "\n",
    "The data set has a sparsity of 99.899%, which is very low even for matrices that are intended to be sparse. We experimented with removing rare artists and including only the top 100 artists, which had minimal effect on the sparsity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rare_artists = data.query(\"plays < 6\"). \\\n",
    "    groupby('artistname').size().reset_index(name='users_listening_to_artist'). \\\n",
    "    query(\"users_listening_to_artist < 10\")\n",
    "    \n",
    "# top100_artists = data.groupby('artistname')['plays'].sum().reset_index(name='plays'). \\\n",
    "#    nlargest(100,'plays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reduced_data = data[~data.artistname.isin(rare_artists['artistname'])]\n",
    "\n",
    "print(reduced_data.shape, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = list(np.sort(reduced_data.userid.unique())) # Get our unique users\n",
    "artists = list(reduced_data.artistname.unique()) # Get our unique artists\n",
    "quantity = list(reduced_data.plays) # All of our plays\n",
    "\n",
    "rows = reduced_data.userid.astype('category', categories = users).cat.codes \n",
    "# Get the associated row indices\n",
    "cols = reduced_data.artistname.astype('category', categories = artists).cat.codes \n",
    "# Get the associated column indices\n",
    "plays_sparse = sparse.csr_matrix((quantity, (rows, cols)), shape=(len(users), len(quantity)))\n",
    "\n",
    "plays_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sparsity of the matrix\n",
    "matrix_size = plays_sparse.shape[0]*plays_sparse.shape[1] # Number of possible interactions in the matrix\n",
    "num_plays = len(plays_sparse.nonzero()[0]) # Number of items interacted with\n",
    "sparsity = 100*(1 - (num_plays/matrix_size))\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While 99.898% sparsity is not great, it is an improvement over the previous matrix.\n",
    "\n",
    "For the SVD algorithm, we use the Surprise package. We modify the plays parameter to be a binary indicator of whether someone has listened to an artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# usertotal = data.groupby('userid')['plays'].sum().reset_index(name=\"total_plays\")\n",
    "# normalized_data = pd.merge(reduced_data, usertotal)\n",
    "# normalized_data['normalized_plays'] = normalized_data['plays']/normalized_data['total_plays']\n",
    "# normalized_data.drop(['total_plays'], inplace=True, axis=1)\n",
    "# normalized_data.loc[normalized_data['plays'] != 0, 'plays'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[data['plays'] != 0, 'plays'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0, 1))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "model_data = Dataset.load_from_df(data, reader)\n",
    "model_data.split(n_folds=3)\n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Evaluate performances of our algorithm on the dataset.\n",
    "perf = evaluate(algo, model_data, measures=['RMSE'])\n",
    "print_perf(perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the GridSearch class to tune our hyperparameters. We initially included the 'epoch' parameter, which drastically increased the run time of the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'n_factors': 60, 'lr_all': 0.01, 'reg_all': 0.02}, {'n_factors': 60, 'lr_all': 0.01, 'reg_all': 0.040000000000000001}, {'n_factors': 60, 'lr_all': 0.01, 'reg_all': 0.059999999999999998}, {'n_factors': 60, 'lr_all': 0.01, 'reg_all': 0.080000000000000002}, {'n_factors': 60, 'lr_all': 0.01, 'reg_all': 0.10000000000000001}, {'n_factors': 60, 'lr_all': 0.01, 'reg_all': 0.12000000000000001}]\n",
      "------------\n",
      "Parameters combination 1 of 6\n",
      "params:  {'n_factors': 60, 'lr_all': 0.01, 'reg_all': 0.02}\n",
      "------------\n",
      "Mean RMSE: 0.0056\n",
      "------------\n",
      "------------\n",
      "Parameters combination 2 of 6\n",
      "params:  {'n_factors': 60, 'lr_all': 0.01, 'reg_all': 0.040000000000000001}\n",
      "------------\n",
      "Mean RMSE: 0.0028\n",
      "------------\n",
      "------------\n",
      "Parameters combination 3 of 6\n",
      "params:  {'n_factors': 60, 'lr_all': 0.01, 'reg_all': 0.059999999999999998}\n",
      "------------\n",
      "Mean RMSE: 0.0018\n",
      "------------\n",
      "------------\n",
      "Parameters combination 4 of 6\n",
      "params:  {'n_factors': 60, 'lr_all': 0.01, 'reg_all': 0.080000000000000002}\n",
      "------------\n",
      "Mean RMSE: 0.0013\n",
      "------------\n",
      "------------\n",
      "Parameters combination 5 of 6\n",
      "params:  {'n_factors': 60, 'lr_all': 0.01, 'reg_all': 0.10000000000000001}\n",
      "------------\n",
      "Mean RMSE: 0.0010\n",
      "------------\n",
      "------------\n",
      "Parameters combination 6 of 6\n",
      "params:  {'n_factors': 60, 'lr_all': 0.01, 'reg_all': 0.12000000000000001}\n",
      "------------\n",
      "Mean RMSE: 0.0008\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# param_grid = {'n_factors': np.arange(60,140,20),\n",
    "#               'lr_all': np.arange(0.002,0.014, 0.004),'reg_all': np.arange(0.02,0.1, 0.02)}\n",
    "param_grid = {'n_factors': [60],'lr_all': [.01],'reg_all': np.arange(0.02,0.14, 0.02)}\n",
    "grid_search = GridSearch(SVD, param_grid, measures=['RMSE'])\n",
    "\n",
    "model_data = Dataset.load_from_df(data[['userid', 'artistname', 'plays']], reader)\n",
    "model_data.split(n_folds=3)\n",
    "\n",
    "grid_search.evaluate(model_data)\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(grid_search.cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding the set of hyperparameters with minimal RMSE (factors = 60, learning rate = 0.01 and regularization = 0.08), we iteratively varied one hyperparameter to see how RMSE changes while others are held constant.\n",
    "\n",
    "For example, we held the learning rate and regularization at their respective optimal values of 0.01 and 0.08, while varying the number of factors from 20 to 120 in increments of 20.\n",
    "\n",
    "We saved three files: reg.csv, learning.csv and factor.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df.to_csv('reg.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output = pd.DataFrame(predictions)\n",
    "#output = output.drop(['r_ui', 'details'], axis=1)\n",
    "\n",
    "#combined = pd.merge(normalized_data,output,left_on=['userid','artistname'],right_on=['uid','iid'])\n",
    "#combined = combined.drop(['uid', 'iid'], axis=1).set_index('userid')\n",
    "#combined.head()\n",
    "\n",
    "##fpr, tpr, thresholds = metrics.roc_curve(combined['normalized_plays'], combined['est'], pos_label=2)\n",
    "##metrics.auc(fpr, tpr)\n",
    "\n",
    "#roc_auc_score(combined['normalized_plays'],combined['est'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
