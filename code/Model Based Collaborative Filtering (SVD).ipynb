{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import random\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import evaluate, print_perf, GridSearch\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "\n",
    "random.seed(561)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#users = pd.read_csv('~/Columbia/Personalization Theory/lastfm-dataset-1K/userid-profile.tsv', header=None)\n",
    "data = pd.read_csv('~/Columbia/Personalization Theory/lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv',\n",
    "                   delimiter=\"\\t\", header=None,\n",
    "                   names = [\"userid\",\"timestamp\",\"artistid\",\n",
    "                            \"artistname\",\"trackid\",\"trackname\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = data.rename(columns={0:'userid', 1:'timestamp', 2:'artistid', 3:'artistname', 4:'trackid', 5:'trackname'})\n",
    "\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>artistid</th>\n",
       "      <th>artistname</th>\n",
       "      <th>trackid</th>\n",
       "      <th>trackname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 23:08:57</td>\n",
       "      <td>f1b1cf71-bd35-4e99-8624-24a6e15f133a</td>\n",
       "      <td>Deep Dish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fuck Me Im Famous (Pacha Ibiza)-09-28-2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:54:10</td>\n",
       "      <td>a7f7df4a-77d8-4f12-8acd-5c60c93f4de8</td>\n",
       "      <td>坂本龍一</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Composition 0919 (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:52:04</td>\n",
       "      <td>a7f7df4a-77d8-4f12-8acd-5c60c93f4de8</td>\n",
       "      <td>坂本龍一</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mc2 (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:42:52</td>\n",
       "      <td>a7f7df4a-77d8-4f12-8acd-5c60c93f4de8</td>\n",
       "      <td>坂本龍一</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hibari (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:42:11</td>\n",
       "      <td>a7f7df4a-77d8-4f12-8acd-5c60c93f4de8</td>\n",
       "      <td>坂本龍一</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mc1 (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        userid           timestamp                              artistid  \\\n",
       "0  user_000001 2009-05-04 23:08:57  f1b1cf71-bd35-4e99-8624-24a6e15f133a   \n",
       "1  user_000001 2009-05-04 13:54:10  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8   \n",
       "2  user_000001 2009-05-04 13:52:04  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8   \n",
       "3  user_000001 2009-05-04 13:42:52  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8   \n",
       "4  user_000001 2009-05-04 13:42:11  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8   \n",
       "\n",
       "  artistname trackid                                   trackname  \n",
       "0  Deep Dish     NaN  Fuck Me Im Famous (Pacha Ibiza)-09-28-2007  \n",
       "1       坂本龍一     NaN           Composition 0919 (Live_2009_4_15)  \n",
       "2       坂本龍一     NaN                        Mc2 (Live_2009_4_15)  \n",
       "3       坂本龍一     NaN                     Hibari (Live_2009_4_15)  \n",
       "4       坂本龍一     NaN                        Mc1 (Live_2009_4_15)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the mini-project, we are using a smaller dataset. The following transformations will convert the dataset to use number of plays as our metric, grouped by user and artist.\n",
    "\n",
    "To help with our data cleaning and setting up the matrices, we used [this website](https://jessesw.com/Rec-System/) to guide us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.groupby(['userid', 'artistname']).size().reset_index(name='plays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = list(np.sort(data.userid.unique())) # Get our unique users\n",
    "artists = list(data.artistname.unique()) # Get our unique artists\n",
    "quantity = list(data.plays) # All of our plays\n",
    "\n",
    "rows = data.userid.astype('category', categories = users).cat.codes \n",
    "# Get the associated row indices\n",
    "cols = data.artistname.astype('category', categories = artists).cat.codes \n",
    "# Get the associated column indices\n",
    "plays_sparse = sparse.csr_matrix((quantity, (rows, cols)), shape=(len(users), len(quantity)))\n",
    "plays_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sparsity of the matrix\n",
    "matrix_size = plays_sparse.shape[0]*plays_sparse.shape[1] # Number of possible interactions in the matrix\n",
    "num_plays = len(plays_sparse.nonzero()[0]) # Number of items interacted with\n",
    "sparsity = 100*(1 - (num_plays/matrix_size))\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Reduction\n",
    "\n",
    "The sparsity of 99.899% is extremely sparse, even for matrices that are intended to be sparse. We experimented with removing all rare artists, which had minimal effect on the sparsity. Instead, we will include only the top 100 artists, which has some improvement on the sparsity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rare_artists = data.query(\"plays < 6\"). \\\n",
    "    groupby('artistname').size().reset_index(name='users_listening_to_artist'). \\\n",
    "    query(\"users_listening_to_artist < 10\")\n",
    "    \n",
    "#top100_artists = data.groupby('artistname')['plays'].sum().reset_index(name='plays'). \\\n",
    "#    nlargest(100,'plays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reduced_data = data[~data.artistname.isin(rare_artists['artistname'])]\n",
    "\n",
    "print(reduced_data.shape, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = list(np.sort(reduced_data.userid.unique())) # Get our unique users\n",
    "artists = list(reduced_data.artistname.unique()) # Get our unique artists\n",
    "quantity = list(reduced_data.plays) # All of our plays\n",
    "\n",
    "rows = reduced_data.userid.astype('category', categories = users).cat.codes \n",
    "# Get the associated row indices\n",
    "cols = reduced_data.artistname.astype('category', categories = artists).cat.codes \n",
    "# Get the associated column indices\n",
    "plays_sparse = sparse.csr_matrix((quantity, (rows, cols)), shape=(len(users), len(quantity)))\n",
    "\n",
    "plays_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sparsity of the matrix\n",
    "matrix_size = plays_sparse.shape[0]*plays_sparse.shape[1] # Number of possible interactions in the matrix\n",
    "num_plays = len(plays_sparse.nonzero()[0]) # Number of items interacted with\n",
    "sparsity = 100*(1 - (num_plays/matrix_size))\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While 99.898% sparsity is not great, it is an improvement over the previous matrix, and so we will use this to set up our brute force model.\n",
    "\n",
    "For SVD, we use the `surprise` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usertotal = data.groupby('userid')['plays'].sum().reset_index(name=\"total_plays\")\n",
    "normalized_data = pd.merge(reduced_data, usertotal)\n",
    "normalized_data['normalized_plays'] = normalized_data['plays']/normalized_data['total_plays']\n",
    "normalized_data.drop(['total_plays'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalized_data[(normalized_data.plays > 0)]['plays'] = 1\n",
    "normalized_data.loc[normalized_data['plays'] != 0, 'plays'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0, 1))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "model_data = Dataset.load_from_df(normalized_data[['userid', 'artistname', 'plays']], reader)\n",
    "\n",
    "model_data.split(n_folds=3)\n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD(reg_all=.1)\n",
    "\n",
    "# Evaluate performances of our algorithm on the dataset.\n",
    "perf = evaluate(algo, model_data, measures=['RMSE', 'MAE'])\n",
    "\n",
    "print_perf(perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'n_epochs': np.arange(10,30, 1), 'lr_all': np.arange(0.002,0.014, 0.001),\n",
    "              'reg_all': np.arange(0.02,0.6, 0.02)}\n",
    "grid_search = GridSearch(SVD, param_grid, measures=['RMSE', 'MAE'])\n",
    "\n",
    "model_data = Dataset.load_from_df(normalized_data[['userid', 'artistname', 'plays']], reader)\n",
    "model_data.split(n_folds=3)\n",
    "\n",
    "grid_search.evaluate(model_data)\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(grid_search.cv_results)\n",
    "#results_df.to_csv(SVD_results, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output = pd.DataFrame(predictions)\n",
    "#output = output.drop(['r_ui', 'details'], axis=1)\n",
    "\n",
    "#combined = pd.merge(normalized_data,output,left_on=['userid','artistname'],right_on=['uid','iid'])\n",
    "#combined = combined.drop(['uid', 'iid'], axis=1).set_index('userid')\n",
    "#combined.head()\n",
    "\n",
    "##fpr, tpr, thresholds = metrics.roc_curve(combined['normalized_plays'], combined['est'], pos_label=2)\n",
    "##metrics.auc(fpr, tpr)\n",
    "\n",
    "#roc_auc_score(combined['normalized_plays'],combined['est'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
