{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score as AUC\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_split(data, validation_ratio = 0.15, test_ratio = 0.15):\n",
    "    \"\"\"\n",
    "    Function to split data into train, validation and test based on timestamps\n",
    "    \n",
    "    https://stackoverflow.com/questions/42395258/\n",
    "    \n",
    "    \"\"\"\n",
    "    train_ratio = 1 - validation_ratio - test_ratio\n",
    "    \n",
    "    data['time_rank'] = data.groupby('userid')['timestamp'].rank()\n",
    "    data['user_all_songs_count'] = data['userid'].map(data.groupby('userid')['timestamp'].apply(len))\n",
    "    data['scaled_time_rank'] = data['time_rank']/ data['user_all_songs_count']\n",
    "    \n",
    "    data.drop(['time_rank', 'user_all_songs_count'], axis=1, inplace=True)\n",
    "    \n",
    "    train_data = data.loc[data['scaled_time_rank'] <= train_ratio, :]\n",
    "    validation_data = data.loc[(data['scaled_time_rank'] <= (1 - test_ratio)) & (data['scaled_time_rank'] > train_ratio), :]\n",
    "    test_data = data.loc[(data['scaled_time_rank'] > (train_ratio + validation_ratio)), :]\n",
    "    train_data.drop(['scaled_time_rank', 'timestamp', 'userid'], axis=1, inplace=True)\n",
    "    validation_data.drop(['scaled_time_rank', 'timestamp', 'userid'], axis=1, inplace=True)\n",
    "    test_data.drop(['scaled_time_rank', 'timestamp', 'userid'], axis=1, inplace=True)\n",
    "    return train_data, validation_data, test_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pandas_df = pd.read_csv('data_engineered_features500.csv') \n",
    "pandas_df[\"gender_int\"] = 0\n",
    "pandas_df.loc[pandas_df[\"gender\"] == \"m\", \"gender_int\"] = 1\n",
    "pandas_df.loc[pandas_df[\"gender\"] == \"f\", \"gender_int\"] = 2\n",
    "pandas_df.drop([\"track-name\",\"artist-name\", \"songlength\", \"gender\"], axis=1, inplace=True)\n",
    "pandas_df = pandas_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekend</th>\n",
       "      <th>daytime</th>\n",
       "      <th>user-track-total-count</th>\n",
       "      <th>track-weekday-count</th>\n",
       "      <th>track-daytime-count</th>\n",
       "      <th>last-seen-song</th>\n",
       "      <th>...</th>\n",
       "      <th>user-song-skip-percentage</th>\n",
       "      <th>user-artist-skips</th>\n",
       "      <th>user-artist-skip-percentage</th>\n",
       "      <th>global-song-skips</th>\n",
       "      <th>global-artist-skips</th>\n",
       "      <th>artist_total_count</th>\n",
       "      <th>song_total_count</th>\n",
       "      <th>global-song-skip-percentage</th>\n",
       "      <th>global-artist-skip-percentage</th>\n",
       "      <th>gender_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2006-08-13 13:59:20</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2006-08-13 14:03:29</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2006-08-13 14:10:43</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2006-08-13 15:44:17</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2006-08-13 16:46:52</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userid            timestamp  weekday  hour  weekend  daytime  \\\n",
       "0  user_000001  2006-08-13 13:59:20        6    13        1        3   \n",
       "1  user_000001  2006-08-13 14:03:29        6    14        1        3   \n",
       "2  user_000001  2006-08-13 14:10:43        6    14        1        3   \n",
       "3  user_000001  2006-08-13 15:44:17        6    15        1        3   \n",
       "4  user_000001  2006-08-13 16:46:52        6    16        1        3   \n",
       "\n",
       "   user-track-total-count  track-weekday-count  track-daytime-count  \\\n",
       "0                       1                    1                    1   \n",
       "1                       1                    1                    1   \n",
       "2                       1                    1                    1   \n",
       "3                       1                    1                    1   \n",
       "4                       1                    1                    1   \n",
       "\n",
       "   last-seen-song     ...      user-song-skip-percentage  user-artist-skips  \\\n",
       "0             0.0     ...                            0.0                  0   \n",
       "1             0.0     ...                            0.0                  0   \n",
       "2             0.0     ...                            0.0                  0   \n",
       "3             0.0     ...                            0.0                  0   \n",
       "4             0.0     ...                            1.0                  1   \n",
       "\n",
       "   user-artist-skip-percentage  global-song-skips  global-artist-skips  \\\n",
       "0                     0.000000                  0                    0   \n",
       "1                     0.000000                  0                    0   \n",
       "2                     0.000000                  0                    0   \n",
       "3                     0.000000                  0                    0   \n",
       "4                     0.333333                  1                    1   \n",
       "\n",
       "   artist_total_count  song_total_count  global-song-skip-percentage  \\\n",
       "0                   1                 1                          0.0   \n",
       "1                   2                 1                          0.0   \n",
       "2                   3                 1                          0.0   \n",
       "3                   1                 1                          0.0   \n",
       "4                   3                 1                          1.0   \n",
       "\n",
       "   global-artist-skip-percentage  gender_int  \n",
       "0                            0.0           1  \n",
       "1                            0.0           1  \n",
       "2                            0.0           1  \n",
       "3                            0.0           1  \n",
       "4                            1.0           1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = data_split(pandas_df, validation_ratio = 0.15, test_ratio = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = np.array(train_data[\"skipped\"])\n",
    "validation_y = np.array(validation_data[\"skipped\"])\n",
    "test_y = np.array(test_data[\"skipped\"])\n",
    "\n",
    "train_data.drop([\"skipped\"], axis=1, inplace=True)\n",
    "validation_data.drop([\"skipped\"], axis=1, inplace=True)\n",
    "test_data.drop([\"skipped\"], axis=1, inplace=True)\n",
    "\n",
    "features_list = list(train_data)\n",
    "train_data = (train_data - pandas_df.mean())/pandas_df.std()\n",
    "validation_data = (train_data - pandas_df.mean())/pandas_df.std()\n",
    "test_data = (test_data - pandas_df.mean())/pandas_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.shape(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neural_net_model():\n",
    "    # create model\n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(10, input_dim=14, activation='relu',\n",
    "                                    kernel_initializer='glorot_normal'))\n",
    "    \n",
    "    #model.add(tf.keras.layers.Dropout(0.1)\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    sgd = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the Neural Network model\n",
    "# Using Scikit-Learn wrapper in Keras, which is now in Tensorflow\n",
    "deep_net = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=neural_net_model, epochs=5, \n",
    "                                                          batch_size=128, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_model = LR(penalty='l2', dual=False, tol=0.001, C=1, fit_intercept=True, \n",
    "                  intercept_scaling=1, class_weight=None, random_state=42, \n",
    "                  solver='liblinear', max_iter=50, multi_class='ovr', \n",
    "                  verbose=0, warm_start=False, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#oof_prediction = cross_val_predict(linear_model, np.array(pandas_df), y, cv=5, method='predict_proba')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_net.fit(np.array(train_data), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_prediction = deep_net.predict_proba(np.array(validation_data))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_auc = AUC(validation_y, val_prediction)\n",
    "print(\"Validation AUC Score:\", val_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
